{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "@author: Aravindhan Poopathy\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "import glob\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#reading the files from the input directories:\n",
    "\n",
    "input_dir_coats    = 'C:/Users/HP/Downloads/fashionCNN/rawData/coats&jackets/'\n",
    "input_dir_sweaters = 'C:/Users/HP/Downloads/fashionCNN/rawData/sweaters/'\n",
    "input_dir_teescasuals = 'C:/Users/HP/Downloads/fashionCNN/rawData/tees&casuals/'\n",
    "input_dir_shirts   ='C:/Users/HP/Downloads/fashionCNN/rawData/shirt/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.listdir(input_dir_coats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1310\n",
      "1090\n",
      "762\n",
      "1457\n"
     ]
    }
   ],
   "source": [
    "#file path creation and labelling\n",
    "\n",
    "path_list = []\n",
    "\n",
    "for i,filec in enumerate(os.listdir(input_dir_coats)):\n",
    "    path_list.append(os.path.join(input_dir_coats, filec))\n",
    "i+=1\n",
    "coatslabel = [0] * i\n",
    "\n",
    "print(len(coatslabel))\n",
    "\n",
    "for i,files in enumerate(os.listdir(input_dir_sweaters)):\n",
    "    path_list.append(os.path.join(input_dir_sweaters, files))\n",
    "i+=1\n",
    "sweaterlabel = [1] * i\n",
    "\n",
    "print(len(sweaterlabel))\n",
    "\n",
    "\n",
    "for i,filet in enumerate(os.listdir(input_dir_teescasuals)):\n",
    "    path_list.append(os.path.join(input_dir_teescasuals, filet))\n",
    "i+=1\n",
    "teeslabel = [2] * i\n",
    "\n",
    "print(len(teeslabel))\n",
    "\n",
    "for i,filesh in enumerate(os.listdir(input_dir_shirts)):\n",
    "    path_list.append(os.path.join(input_dir_shirts, filesh))\n",
    "i+=1\n",
    "shirtlabel = [3] * i\n",
    "\n",
    "print(len(shirtlabel))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4619"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input label\n",
    "input_labels = labels = coatslabel + sweaterlabel + teeslabel  + shirtlabel\n",
    "# input_labels\n",
    "labarr=np.asarray(labels)\n",
    "len(labarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ima = cv2.imread(\"C:/Users/HP/Downloads/fashionCNN/rawData/coats&jackets/1.jpg\")\n",
    "type(ima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the input data and resizing it as the data scrapped from different websites will in different sizes\n",
    "\n",
    "# input_data = [cv2.imread(x) for x in path_list]\n",
    "\n",
    "input_data = []\n",
    "\n",
    "for img in path_list:\n",
    "    image = Image.open(img).convert('RGB')\n",
    "    sqrWidth = np.ceil(np.sqrt(image.size[0]*image.size[1])).astype(int)\n",
    "    new_image = image.resize((sqrWidth,sqrWidth))\n",
    "    new_image = new_image.resize((100,100))\n",
    "#converting it to numpy array as Image List type cannot be converted to an array    \n",
    "    final_image = np.array(new_image)\n",
    "    input_data.append(final_image)\n",
    "\n",
    "type(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4619, 100, 100, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data=np.asarray(input_data)\n",
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#shufflig the data and the label equally for eleminating overfitting\n",
    "\n",
    "arr = np.arange(len(labarr))\n",
    "np.random.shuffle(arr)\n",
    "data = in_data[arr]\n",
    "labarr = labarr[arr]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924, 32, 32, 3)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and Test split\n",
    "\n",
    "X_train, X_test, label_train, label_test = train_test_split(in_data, labarr, test_size=0.2)\n",
    "\n",
    "X_train.shape\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output classes :  [0 1 2 3]\n",
      "Total number of outputs :  4\n"
     ]
    }
   ],
   "source": [
    "# Find the unique numbers from the train labels\n",
    "classes = np.unique(label_train)\n",
    "nClasses = len(classes)\n",
    "print('Output classes : ', classes)\n",
    "print('Total number of outputs : ', nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (3694, 32, 32, 3) (3694,)\n",
      "Testing data shape :  (924, 32, 32, 3) (924,)\n"
     ]
    }
   ],
   "source": [
    "# Find the shape of input images and create the variable input_shape\n",
    "nRows,nCols,nDims = X_train.shape[1:]\n",
    "train_data = X_train.reshape(X_train.shape[0], nRows, nCols, nDims)\n",
    "test_data = X_test.reshape(X_test.shape[0], nRows, nCols, nDims)\n",
    "print('Training data shape : ', X_train.shape, label_train.shape)\n",
    "\n",
    "print('Testing data shape : ', X_test.shape, label_test.shape)\n",
    "input_shape = (nRows, nCols, nDims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change to float datatype\n",
    "train_data = train_data.astype('float32')\n",
    "test_data = test_data.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "train_data /= 255\n",
    "test_data /= 255\n",
    "\n",
    "# Change the labels from integer to categorical data\n",
    "train_labels_one_hot = to_categorical(label_train,nClasses)\n",
    "test_labels_one_hot = to_categorical(label_test,nClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label 0 :  3\n",
      "After conversion to categorical ( one-hot ) :  [ 0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# Display the change for category label using one-hot encoding\n",
    "print('Original label 0 : ', label_train[0])\n",
    "print('After conversion to categorical ( one-hot ) : ', train_labels_one_hot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Model creation:\n",
    "\n",
    "def createModel():\n",
    "    \n",
    "    model = Sequential()\n",
    "    # The first two layers with 32 filters of window size 3x3\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model1 = createModel()\n",
    "batch_size = 256\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "          zoom_range = 0.2,  \n",
    "           fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15/15 [==============================] - 1s 67ms/step - loss: 1.3666 - acc: 0.3120 - val_loss: 1.3700 - val_acc: 0.2922\n",
      "Epoch 2/10\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 1.3623 - acc: 0.3211 - val_loss: 1.3650 - val_acc: 0.2922\n",
      "Epoch 3/10\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 1.3601 - acc: 0.3191 - val_loss: 1.3662 - val_acc: 0.2922\n",
      "Epoch 4/10\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 1.3577 - acc: 0.3189 - val_loss: 1.3649 - val_acc: 0.2922\n",
      "Epoch 5/10\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 1.3596 - acc: 0.3229 - val_loss: 1.3658 - val_acc: 0.2922\n",
      "Epoch 6/10\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 1.3591 - acc: 0.3225 - val_loss: 1.3665 - val_acc: 0.2922\n",
      "Epoch 7/10\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 1.3589 - acc: 0.3196 - val_loss: 1.3654 - val_acc: 0.2922\n",
      "Epoch 8/10\n",
      "15/15 [==============================] - 1s 58ms/step - loss: 1.3581 - acc: 0.3225 - val_loss: 1.3651 - val_acc: 0.2922\n",
      "Epoch 9/10\n",
      "15/15 [==============================] - 1s 59ms/step - loss: 1.3602 - acc: 0.3234 - val_loss: 1.3657 - val_acc: 0.2922\n",
      "Epoch 10/10\n",
      "15/15 [==============================] - 1s 57ms/step - loss: 1.3596 - acc: 0.3212 - val_loss: 1.3658 - val_acc: 0.2922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8c2c0e12e8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit_generator(datagen.flow(train_data, train_labels_one_hot,\n",
    "           batch_size=batch_size),\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(test_data, test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924/924 [==============================] - 0s 133us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3655565688104341, 0.29220779246582096]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(test_data, test_labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
